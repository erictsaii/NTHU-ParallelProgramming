# 113062526 蔡芝泰 HW1 Report 
## Implementation
### How do you handle an arbitrary number of input items and processes?
* 為了計算offset的方便性，我讓每一個process可以分到floor(n / size)個element，如果 input 無法被process 整除，那rank為size-1的process 就會分到額外的n % size個element，如此一來，不論input和process的數量為多少，都能夠確保我的程式不會出錯。 
### How do you sort in your program?
#### local sort
* 為了實現資料讀取和local sort的overlapping，我選擇的方法是先透過`MPI_File_read_at`去讀取一半的資料，再透過`MPI_File_iread_at`非同步地去讀另一半，期間會使用`spreadsort`去排序其中一半的資料，等到`MPI_File_iread_at`讀完之後，再用一次`spreadsort`去排序剩下一半的資料，最後再將兩個已排序好的array進行merge，merge的程式碼如下，是一個O(n)的演算法，實測下來優化效果不明顯，但在總秒數上有大約1秒的優化，推測是overlapping所帶來的優化和merge所帶來的overhead相互抵消了。
  ```cpp
  void mergeSortedArrays(float arr1[], int size1, float arr2[], int size2, float mergedArray[], int mergedSize) {
    int i = 0, j = 0, k = 0;
    while (i < size1 && j < size2 && k < mergedSize) {
        if (arr1[i] < arr2[j]) {
            mergedArray[k++] = arr1[i++];
        } else {
            mergedArray[k++] = arr2[j++];
        }
    }
    while (i < size1 && k < mergedSize) {
        mergedArray[k++] = arr1[i++];
    }
    while (j < size2 && k < mergedSize) {
        mergedArray[k++] = arr2[j++];
    }
  }
  ```

#### odd-even sort
* 在開始每一輪的odd-even sort之前，以odd phase 為例，process 1會傳自己最大的element 給 process 2，而 process 2 則是傳最小的 element 給process 1，如此一來，process 1 和 2就可以知道要不要繼續這次的交換，進而減少不必要的資料傳輸時間。
* 如果此次交換是必要的，那就透過`MPI_Sendrecv` 來把自己的資料傳給neighbor，同時也把neighbor傳過來的資料做接收，由於此時我們會得到兩個排序好的陣列，可以使用剛剛的`mergeSortedArrays`來進行合併，不需要再額外做一次sorting，一個process會取前一半的資料，另一個process會取後一半的資料，所以merge的實作上也會有些許不同，取後一半的演算法如下。
  ```cpp
  void mergeSortedArrays2(float arr1[], int size1, float arr2[], int size2, float mergedArray[], int mergedSize) {
    int i = size1 - 1, j = size2 - 1, k = mergedSize - 1;
    while (i >= 0 && j >= 0 && k >= 0) {
        if (arr1[i] > arr2[j]) {
            mergedArray[k--] = arr1[i--];
        } else {
            mergedArray[k--] = arr2[j--];
        }
    }
    while (i >= 0 && k >= 0) {
        mergedArray[k--] = arr1[i--];
    }
    while (j >= 0 && k >= 0) {
        mergedArray[k--] = arr2[j--];
    }
  }
  ```
  在循環size+1個phase後，就可以完成odd-even sort。
### Other efforts you’ve made in your program.
* 使用`module load openmpi`。
* 若兩個array要進行交換時，不需要將裡面的element進行資料搬移，只需將指向array開頭的pointer互相交換即可。
* 有些乘除的計算可以透過一個變數存起來，不需要一直重複計算。
* 盡量去reuse宣告好的變數和array，而非重新宣告。


## Experiment & Analysis
### i. Methodology
#### (a). System Spec
* 課程提供的Apollo CPU server。
#### (b). Performance Metrics
* 我使用Nsight作為profiler。
* `Communacation time`是`MPI_Sendrecv`所花的時間。
* `IO time`是`MPI_File_open`, `MPI_File_read_at`, `MPI_File_iread_at`, `MPI_Wait`, `MPI_File_write_at`, `MPI_File_close`所加總的的時間。
* `Compute time`是透過總執行時間扣掉`communacation time`和`IO time`所得。
* 所有的數據都會是全部process平均後的結果。
### ii. Plots: Speedup Factor & Profile
#### Experimental Method:
* Test Case Description: 我使用的是testcase 36，element的數量為536869888個，執行時間夠長，能夠看出在各種環境配置下的差異。
* Parallel Configurations: 在single node的實驗中，我嘗試了1, 4, 8, 12個process;而在four nodes的實驗中，則是使用了4, 12, 24, 48個process。
#### Performance Measurement:
* single node (unit: second)
  | # of process | I/O   | communication | compute |
  |:------------ |:----- |:------------- |:------- |
  | 1            | 2.067 | 0             | 7.88    |
  | 4            | 1.91  | 1.74          | 2.14    |
  | 8            | 1.623 | 2.26          | 1.207   |
  | 12           | 1.86  | 2.18          | 1.07    |
* four nodes (unit: second)
  | # of process | I/O   | communication | compute |
  |:------------ |:----- |:------------- |:------- |
  | 4            | 0.911 | 2.1           | 2.076   |
  | 12           | 1.49  | 1.977         | 0.883   |
  | 24           | 2.23  | 1.8           | 0.62    |
  | 48           | 1.677 | 2.05          | 0.43    |

#### Analysis of Results:
![image](https://hackmd.io/_uploads/BJ6PQgnxJe.png)
![image](https://hackmd.io/_uploads/B10YElngyl.png)
* 對於single node來說，我認為效能瓶頸主要是在communication，其次是在I/O，因為隨著process數量的上升compute time是有下降的，但communication time反而是有點上升的趨勢，而I/O則是維持在一定的秒數，綜合以上原因，導致了在process數量從8變成12之後，speedup卻微微下降了一點。
![image](https://hackmd.io/_uploads/B1JlMengkx.png)
![image](https://hackmd.io/_uploads/Bk5-Hx3eye.png)
* 對於four nodes來說，我認為效能瓶頸也是在communication和I/O，因為compute time是有隨著process數量上升而下降的，但I/O和communication卻降不下去，占了整個執行時間的蠻大比例。


#### Optimization Strategies:
* 我透過nsys有觀察到I/O在每個process的執行時間其實浮動很大，推測是已經達到了disk的bandwidth上限，由於`MPI_File_open`是collective function，所以會變成全部process一起open file之後再一起write file，也因此我將open output file的位置提前，放在開始odd-even sort之前，這樣若有一些process先做完了odd-even sort，他就可以先進行write file，做了這個優化之後在scoreboard上從86秒進步到80秒。
* communication的話有想過可以去嘗試用`Isend`/`Irecv`去取代`Sendrecv`，進而去overlap send/recv和merge，這樣理論上是可以降低執行時間，不過這個想法還未實作。

### iii. Discussion
#### Compare I/O, CPU, Network performance. Which is/are the bottleneck(s)? Why? How could it be improved?
* 根據我的實驗結果，我認為是I/O跟Network都是，因為在process數量變多的情況下，compute time都能夠降低，但是I/O跟commnication time會維持差不多的值甚至變高。若能夠升級硬體設備一定能有很好的效果，只是在process數量真的太多的時候應該還是會達到一個上限。
#### Compare scalability. Does your program scale well? Why or why not? How can you achieve better scalability?
* 以speedup factor來說，這個程式的scalability並不好，因為I/O和communication占了總執行時間的滿大部分，單純在compute time加速的效果沒辦法影響總執行時間太多。若可以透過overlap/硬體升級等方法將I/O和communication的時間降低，變成compute time在dominate總執行時間，那程式的scalability就能夠提高。

### iv、Others 
#### 每個process的MPI_Sendrecv執行時間差異很大
![image](https://hackmd.io/_uploads/Byy9XMpl1e.png)
* 由上圖可以看到，這是在single node上跑12個process的結果，testcase一樣是36，最短的執行時間跟最長的差了將近兩倍，若可以將process在執行`MPI_Sendrecv`的時間變的平均一點也會是個很好的優化。

## Experiences / Conclusion
* 這次作業想了很多優化的技巧，秒數也從一開始一百多秒逐漸降低到八十秒，實作起來很有成就感，很多coding上的小細節若都有注意的話也會有很不錯的優化效果，nsys在使用上也蠻方便的，功能也很好，可以視覺化整支程式的執行順序跟時間，讓我獲益良多。
